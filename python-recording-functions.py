#!/usr/bin/env python

from picamera2 import Picamera2, Preview
from picamera2.encoders import JpegEncoder
from picamera2.encoders import H264Encoder
from sys import getsizeof
import time
import numpy
import cv2
from PIL import Image
import os

def picam2_record_mjpeg(filename, outdir, recording_time=20, quality=95, size=(4056,3040), imformat="RGB888", fps=6, buffer_count=2):
	frame_duration_us = int(1/fps * 10**6)
	picam2 = Picamera2()
	video_config = picam2.create_video_configuration(main={"size": size, "format": imformat}, controls={"FrameDurationLimits": (frame_duration_us, frame_duration_us)}, buffer_count=2)
	picam2.align_configuration(video_config)
	picam2.configure(video_config)

	picam2.start_preview()
	encoder = JpegEncoder(q=quality)
	output = outdir+filename

	picam2.start()
	time.sleep(2)
	picam2.start_encoder(encoder,output,pts=outdir+filename+"_pts.txt")
	#picam2.start_recording(encoder,output,pts=outdir+filename+"_pts.txt")

	time.sleep(recording_time)
	
	picam2.stop()
	picam2.stop_encoder()
	
	


	
def folder_jpgs2mjpeg(dirpath):
	cmd = 'for i in ' + dirpath + '*.jpg: do ffmpeg -i "$i" "${i%.*}.mjpeg"; done'
	os.system(cmd)
	




def picam2_YUV420array2mjpeg(recording_time=5, quality="maximum", fps=6, outdir='/mnt/bombusbox/burstcapturejpgs/', filename='testpicam2_yuv2vid', imtype="yuv"): #make options "yuv", "rgb", "y", "all"
	
	picam2 = Picamera2()
	preview = picam2.create_preview_configuration({"format": "YUV420", "size": (4032,3040)})
	picam2.configure(preview)
	picam2.start()

	time.sleep(2)
	start_time = time.time()
	
	frames_dict = {}
	i = 0
	
	print("beginning video capture")
	while ( (time.time() - start_time) < recording_time) or (i <= fps*recording_time):
		timestamp = time.time() - start_time

		yuv420 = picam2.capture_array()
		
		if imtype == "y":
			yuv420 = yuv420[0:3040, :]
		frames_dict[f"frame_{i:03d}"] = [yuv420, timestamp]
		time.sleep(1/(fps+1))
		i += 1
	print(f'finished capturing frames to arrays, captured {i} frames in {time.time()-start_time}')
	sizeof = getsizeof(frames_dict)
	print(f"Size of dictionary storing the frames: {sizeof}")
	
	if imtype =="y":
		for frame_number in frames_dict:
			imlist = frames_dict[frame_number]
			array = imlist[0]
			y_im = Image.fromarray(array, mode="L") #L meaning a single 8-bit channel, greyscale
			y_im.save(outdir+frame_number+".jpg", quality=quality)
	
	elif imtype =="yuv":
		for frame_number in frames_dict:
			imlist = frames_dict[frame_number]
			array = imlist[0]
			yuv_im = Image.fromarray(array, mode="YCbCr") #YCbCr meaning 3x8-bit channels for YUV
			yuv_im.save(outdir+filename+".jpg", quality=quality)
	
	elif imtype =="rgb":
		for frame_number in frames_dict:
			imlist = frames_dict[frame_number]
			array = imlist[0]
			yuv_im = Image.fromarray(array, mode="YCbCr")
			rgb_im = cv2.cvtColor(yuv_im, cv2.COLOR_YUV420p2RGB)
			rgb_im.save(outdir+filename+".jpg", quality=quality)
	
	elif imtype == "all":
		for frame_number in frames_dict:
			imlist = frames_dict[frame_number]
			array = imlist[0]
			yuv_im = Image.fromarray(array, mode="YCbCr")
			y_im = Image.fromarray(array, mode="L")
			rgb_im = cv2.cvtColor(yuv_im, cv2.COLOR_YUV420p2RGB)
			y_im.save(outdir+filename+".jpg", quality=quality)
			yuv_im.save(outdir+filename+".jpg", quality=quality)
			rgb_im.save(outdir+filename+".jpg", quality=quality)
	
	else:
		print("Error: imtype must equal either 'y', 'yuv', 'rgb', or 'all'")
		return print("Exit code: 1")

	cmd = 'for i in ' + outdir + '*.jpg: do ffmpeg -i "$i" "${i%.*}.mjpeg"; done'
	os.system(cmd)


#def write_jpgs2mp4(numframes, jpgdir='/mnt/bombusbox/burstcapturejpgs', cv2.VideoWriter_fourcc(*'mp4'), fps=10, size=(4032,3040):
	


def picam2_YUV420arraycapture_timetest(recording_time=10, fps=15, quality="maximum", outdir='/mnt/bombusbox/burstcapturejpgs/', filename='testpicam2_yuv2vid', container="dict",imtype="y"): #make options "yuv", "rgb", "y", "all"

	picam2 = Picamera2()
	preview = picam2.create_preview_configuration({"format": "YUV420", "size": (4032,3040)})
	picam2.configure(preview)
	picam2.start()

	time.sleep(2)
	start_time = time.time()
	
	frames_dict = {}
	i = 0
	
	print("beginning video capture")
	while ( (time.time() - start_time) < recording_time): #or (i <= fps*recording_time):
		timestamp = time.time() - start_time
		
		yuv420 = picam2.capture_array()
		
		if imtype=="y" and container=="dict": 
			yuv420 = yuv420[0:3040, :]
			frames_dict[f"frame_{i:03d}"] = [yuv420, timestamp]
			#time.sleep(1/(fps+10))
			i += 1
		
	print(f'finished capturing frames to arrays, captured {i} frames in {time.time()-start_time}')
	sizeof = getsizeof(frames_dict)
	print(f"Size of dictionary storing the frames: {sizeof}")
	
	for frame in frames_dict:
		print(frame_number, frames_dict[frame_number][1])
		
	if imtype =="y":
		timestamps = {}
		save_time = time.time()
		for frame_number in frames_dict:
			imlist = frames_dict[frame_number]
			frame_array = imlist[0]
			y_im = Image.fromarray(frame_array, mode="L") #L meaning a single 8-bit channel, greyscale
			y_im.save(outdir+frame_number+".jpg", quality=quality)
			timestamps[frame_number] = time.time() - save_time
		
		end_time = time.time()
		
		for frame_number in timestamps:
			print(f'{frame_number}: {timestamps[frame_number]} seconds')
			
		print(f'wrote {int(len(frames_dict))} images in {end_time - save_time} seconds.\nThats an average of {int(len(frames_dict)) / (end_time - save_time)} frames per second!')


























### date is 5/30, trying to use just opencv to write to .mp4 or h265
def arraycapture_2_mp4(recording_time=5, codec = 'mp4', quality="maximum", fps=6, outdir='/mnt/bombusbox/burstcapturejpgs/', filename='testpicam2_yuv2vid', imtype="yuv"):
	
	import cv2
	import Picamera2
	
	picam2 = Picamera2()
	preview = picam2.create_preview_configuration({"format": "YUV420", "size": (4032,3040)})
	picam2.configure(preview)
	picam2.start()

	time.sleep(2)
	start_time = time.time()
	
	#frames_dict = {}
	frames_list = []
	i = 0
	
	print("beginning video capture")
	while ( (time.time() - start_time) < recording_time): #or (i <= fps*recording_time):
		timestamp = time.time() - start_time
		
		yuv420 = picam2.capture_array()
		frames_list.append([yuv420, timestamp])
		#yuv420 = yuv420[0:3040, :]
		#frames_dict[f"frame_{i:03d}"] = [yuv420, timestamp]
		#time.sleep(1/(fps+10))
		i += 1
		
	print(f'finished capturing frames to arrays, captured {i} frames in {time.time()-start_time}')
	sizeof = getsizeof(frames_dict)
	sizeof = getsizeof(frames_list)
	print(f"Size of dictionary storing the frames: {sizeof}")
	
	if codec == 'mp4':
		vid_fourcc = VideoWriter_fourcc(*'MP4V')
	elif code == 'h265':
		#look into this for HEVC encoding: https://stackoverflow.com/questions/61260182/how-to-output-x265-compressed-video-with-cv2-videowriter
	
	out = cv2.VideoWriter('testvideo.mp4', apiPreference=cv2.CAP_FFMPEG,vid_fourcc,10,(4032,3040))
	
	for i in frames_list:
		frame = i[0]
		out.write(frame)
	out.release()
	cv2.destroyAllWindows()
	
	
# okay this is trying to get the best video compression to work for our videos, making them into HEVC compressed mp4s. Need to use FFMPEG to do it,
# so this function would be run inside of the create mp4 from RAM function, just if HEVC compression is wanted
# otherwise you can just use cv2.VideoWriter to make mp4s. 
# this should be considered an alternative for more experienced users
# right now this is just copied off of the link from above, need to test it and modify it to work inside of the function above
def writeMp4withHEVC_CompressionFromRAM(outdir, filename, frames_list, width, height, fps):
	
	import cv2
	import numpy as np
	import subprocess as sp
	import shlex

	width, height, n_frames, fps = 1344, 756, 50, 25  # 50 frames, resolution 1344x756, and 25 fps

	output_filename = filename + '.mp4'

	# Open ffmpeg application as sub-process
	# FFmpeg input PIPE: RAW images in BGR color format
	# FFmpeg output MP4 file encoded with HEVC codec.
	# Arguments list:
	# -y                   Overwrite output file without asking
	# -s {width}x{height}  Input resolution width x height (1344x756)
	# -pixel_format bgr24  Input frame color format is BGR with 8 bits per color component
	# -f rawvideo          Input format: raw video
	# -r {fps}             Frame rate: fps (25fps)
	# -i pipe:             ffmpeg input is a PIPE
	# -vcodec libx265      Video codec: H.265 (HEVC)
	# -pix_fmt yuv420p     Output video color space YUV420 (saving space compared to YUV444)
	# -crf 24              Constant quality encoding (lower value for higher quality and larger output file).
	# {output_filename}    Output file name: output_filename (output.mp4)
	process = sp.Popen(shlex.split(f'ffmpeg -y -s {width}x{height} -pixel_format bgr24 -f rawvideo -r {fps} -i pipe: -vcodec libx265 -pix_fmt yuv420p -crf 24 {output_filename}'), stdin=sp.PIPE)

	# Build synthetic video frames and write them to ffmpeg input stream.
	for i in frames_list:
		# Build synthetic image for testing ("render" a video frame).
		img = np.full((height, width, 3), 60, np.uint8)
		cv2.putText(img, str(i+1), (width//2-100*len(str(i+1)), height//2+100), cv2.FONT_HERSHEY_DUPLEX, 10, (255, 30, 30), 20)  # Blue number

		# Write raw video frame to input stream of ffmpeg sub-process.
		process.stdin.write(img.tobytes())

	# Close and flush stdin
	process.stdin.close()

	# Wait for sub-process to finish
	process.wait()

	# Terminate the sub-process
	process.terminate()  # Note: We don't have to terminate the sub-process (after process.wait(), the sub-process is supposed to be closed).
		
		
		
    
def trackTagsFromRAM(frames_list):
	
	#edit dict to be passed from outer function?
	aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50) 
	parameters = aruco.DetectorParameters_create()
	
	#edit these to be passed into it from outer function?
	parameters.minMarkerPerimeterRate=0.03
	parameters.adaptiveThreshWinSizeMin=5
	parameters.adaptiveThreshWinSizeStep=6
	parameters.polygonalApproxAccuracyRate=0.06

	frame_num = 0
	noID = []
	raw = []

	for i in frames_list:
		frame = i[0]
		
		try:
		   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # -code copied
		   clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
		   cl1 = clahe.apply(gray)
		   gray = cv2.cvtColor(cl1,cv2.COLOR_GRAY2RGB)
			
		except:
			continue
			
		corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters = parameters)

		for i in range(len(rejectedImgPoints)):
			c = rejectedImgPoints[i][0]
			xmean = c[:,0].mean() #for calculating the centroid
			ymean = c[:,1].mean() #for calculating the centroid
			xmean_top_point = (c[0,0] + c[1,0]) / 2 #for calculating the top point of the tag
			ymean_top_point = (c[0,1] + c[1,1]) / 2 #for calculating the top point of the tag
			noID.append( [frame_num, "X", float(xmean), float(ymean), float(xmean_top_point), float(ymean_top_point), 100, None] ) #[[float(xmean), float(ymean)], [float(xmean_top_point), float(ymean_top_point)]] )
		
		if ids is not None:
			for i in range(len(ids)):
				c = corners[i][0]
				xmean = c[:,0].mean() #for calculating the centroid
				ymean = c[:,1].mean() #for calculating the centroid
				xmean_top_point = (c[0,0] + c[1,0]) / 2 #for calculating the top point of the tag
				ymean_top_point = (c[0,1] + c[1,1]) / 2 #for calculating the top point of the tag
				raw.append( [frame_num, int(ids[i]),float(xmean), float(ymean), float(xmean_top_point), float(ymean_top_point), 100, None] ) #[[float(xmean), float(ymean)], [float(xmean_top_point), float(ymean_top_point)]] )

		frame_num += 1
		
	df = pandas.DataFrame(raw)
	df = pandas.DataFrame(raw)
	df = df.rename(columns = {0:'frame', 1:'ID', 2:'centroidX', 3:'centroidY', 4:'frontX', 5:'frontY', 6:'1cm', 7:'check'})
	df.to_csv(identified_csv, index=False)
	df2 = pandas.DataFrame(noID)
	df2 = pandas.DataFrame(noID)
	df2 = df2.rename(columns = {0:'frame', 1:'ID', 2:'centroidX', 3:'centroidY', 4:'frontX', 5:'frontY', 6:'1cm', 7:'check'})
	df2.to_csv(potential_csv, index=False)

	print("Average number of tags found: " + str(len(df.index)/frame_num))
	
	return df, df2, frame_num
	








		
if __name__ == '__main__':
	
    #picam2_YUV420arraycapture_timetest()
	cv2_arraycapture()
